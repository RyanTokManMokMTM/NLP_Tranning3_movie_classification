{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "web crawler",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNcr+0rtF0E83sV3E9izGWA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RyanTokManMokMTM/NLP_Tranning3_movie_classification/blob/main/movie_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VViNTJ8cEyZH"
      },
      "source": [
        "## Classification the movie"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gbDFMxRNEw6_"
      },
      "source": [
        "#read the movie\n",
        "import csv\n",
        "import pandas as pd\n",
        "myDatas = []\n",
        "\n",
        "df = pd.read_csv(\"./trainMovies.csv\",encoding=\"utf-8\")\n",
        "header = df.columns.values.tolist()\n",
        "myDatas = df.values.tolist()\n",
        "\n",
        "\n",
        "#remove all extra characters in intro\n",
        "for i in myDatas:\n",
        "  i[3] = \"\".join(i[3].strip().split())"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qiB7U6eudY6R"
      },
      "source": [
        "#remove all NA movie\n",
        "newDatas =  [movie for movie in myDatas if (type(movie[1]) == str)]"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FX6S8qwe3ex9"
      },
      "source": [
        "x = [movie[0:1] + movie[2:] for movie in newDatas]\n",
        "y = [movie[1]  for movie in newDatas]"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MXF9P88lHyeq"
      },
      "source": [
        "# get all type"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KkoJRzF3r5Ok"
      },
      "source": [
        "movieType = set()\n",
        "for i in range(len(y)):\n",
        "  y[i] = y[i].split(\",\")[0]"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eG1kQSs5fOR-"
      },
      "source": [
        "# Feature\n",
        "\n",
        "\n",
        "1.   MovieName\n",
        "2.   ReleaseDate\n",
        "3.   Intro(Cut World)\n",
        "\n",
        "# Label\n",
        "1.   Genre[0]\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s_f0sJItETlI"
      },
      "source": [
        "#Load Stop word\n",
        "import codecs \n",
        "fp = codecs.open(\"./stopwords.dat\",\"r\",encoding=\"utf-8\")\n",
        "contents = fp.read()\n",
        "fp.close()"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qf_d_JZb-Oy1"
      },
      "source": [
        "#from sklearn import feature_extraction\n",
        "import jieba\n",
        "import jieba.analyse\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "#get the word\n",
        "#clean all the stop word\n",
        "movDatas = x\n",
        "movDatasLable = y\n",
        "\n",
        "tempCutList = []\n",
        "for (data,lable) in zip(movDatas,movDatasLable):\n",
        "  cutDataList = [data[0],lable]\n",
        "  cutDataList += [word for word in jieba.analyse.extract_tags(data[2],topK=5) if word not in contents]\n",
        "  tempCutList.append(\" \".join(cutDataList))\n"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pCBIBYKMkGst"
      },
      "source": [
        "# Calculate TF-IDF For each Feature"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uHEb_4GgCFbl"
      },
      "source": [
        "vectorizer = CountVectorizer() # counting each word in list\n",
        "transform = TfidfTransformer() # calculate TFIED value for each word\n",
        "tfidf = transform.fit_transform(vectorizer.fit_transform(tempCutList)) #t.fit =>cal tdidf ,#v.fit =>change words to t.f\n",
        "words = vectorizer.get_feature_names() # get all word \n",
        "weight = tfidf.toarray()"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZNp4kZwlb6n1"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "datas = pd.DataFrame(data=weight,columns=words)\n",
        "X_train,X_test,y_train,y_test = train_test_split(datas,movDatasLable,test_size=0.15,random_state=101)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A3LLfTUokBjW"
      },
      "source": [
        "#KNN Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R9XvFxt7IeZC"
      },
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "knn = KNeighborsClassifier(n_neighbors=43,p=2,n_jobs=-1)\n",
        "knn.fit(X_train,y_train)\n",
        "pred = knn.predict(X_test)\n",
        "percent = knn.score(X_test, y_test)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dKODvtrZgWba",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e8d4b951-e474-454c-afaa-a80cdef01915"
      },
      "source": [
        "print(\"Classification matching percentage :%s\" % (percent*100))"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Classification matching percentage :82.68434134217067\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}