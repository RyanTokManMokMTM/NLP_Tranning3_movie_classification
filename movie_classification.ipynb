{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "web crawler",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNYrv/seK/7JS14nhSH6yG3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RyanTokManMokMTM/NLP_Tranning3_movie_classification/blob/main/movie_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VViNTJ8cEyZH"
      },
      "source": [
        "## Classification the movie"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UzXSIHHPUOea",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "9ecb189e-2179-4dae-e1eb-9f76733558f8"
      },
      "source": [
        "'''\n",
        "TODO:\n",
        "According Genre[0] for k,\n",
        "Acording to the\n",
        "'''"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\nTODO:\\nAccording Genre[0] for k,\\nAcording to the\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gbDFMxRNEw6_"
      },
      "source": [
        "#read the movie\n",
        "import csv\n",
        "import pandas as pd\n",
        "myDatas = []\n",
        "\n",
        "df = pd.read_csv(\"./trainMovies.csv\",encoding=\"utf-8\")\n",
        "header = df.columns.values.tolist()\n",
        "myDatas = df.values.tolist()\n",
        "\n",
        "\n",
        "#remove all extra characters in intro\n",
        "for i in myDatas:\n",
        "  i[3] = \"\".join(i[3].strip().split())"
      ],
      "execution_count": 239,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qiB7U6eudY6R"
      },
      "source": [
        "#remove all NA movie\n",
        "newDatas =  [movie for movie in myDatas if (type(movie[1]) == str)]"
      ],
      "execution_count": 241,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FX6S8qwe3ex9"
      },
      "source": [
        "x = [movie[0:1] + movie[2:] for movie in newDatas]\n",
        "y = [movie[1]  for movie in newDatas]"
      ],
      "execution_count": 136,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KkoJRzF3r5Ok"
      },
      "source": [
        "movieType = set()\n",
        "for i in y:\n",
        "  types = i.split(\",\")[0]\n",
        "  movieType.add(types)"
      ],
      "execution_count": 138,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qwy46ZrK3-uZ",
        "outputId": "fe065396-4b46-499e-86b5-70911f8fb3a9"
      },
      "source": [
        "allTypes = list(movieType)\n",
        "for index,value in enumerate(allTypes):\n",
        "  print(index,value)"
      ],
      "execution_count": 142,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 影展\n",
            "1 音樂/歌舞\n",
            "2 科幻\n",
            "3 冒險\n",
            "4 勵志\n",
            "5 劇情\n",
            "6 懸疑/驚悚\n",
            "7 歷史/傳記\n",
            "8 紀錄片\n",
            "9 犯罪\n",
            "10 奇幻\n",
            "11 戲劇\n",
            "12 溫馨/家庭\n",
            "13 戰爭\n",
            "14 動作\n",
            "15 恐怖\n",
            "16 動畫\n",
            "17 喜劇\n",
            "18 愛情\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eG1kQSs5fOR-"
      },
      "source": [
        "# Feature\n",
        "\n",
        "\n",
        "1.   MovieName\n",
        "2.   ReleaseDate\n",
        "3.   Intro(Cut World)\n",
        "\n",
        "# Label\n",
        "1.   Genre[0]\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zwX9VTCo8dC5",
        "outputId": "9d9218ed-d749-4160-d7f1-2e478fdf3c43"
      },
      "source": [
        "!wget  https://raw.githubusercontent.com/foowaa/Chinese_from_dongxiexidian/master/stopwords.dat"
      ],
      "execution_count": 152,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-08-15 08:33:39--  https://raw.githubusercontent.com/foowaa/Chinese_from_dongxiexidian/master/stopwords.dat\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.111.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 13289 (13K) [text/plain]\n",
            "Saving to: ‘stopwords.dat’\n",
            "\n",
            "\rstopwords.dat         0%[                    ]       0  --.-KB/s               \rstopwords.dat       100%[===================>]  12.98K  --.-KB/s    in 0s      \n",
            "\n",
            "2021-08-15 08:33:40 (96.2 MB/s) - ‘stopwords.dat’ saved [13289/13289]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s_f0sJItETlI"
      },
      "source": [
        "#Load Stop word\n",
        "fp = codecs.open(\"./stopwords.dat\",\"r\",encoding=\"utf-8\")\n",
        "contents = fp.read()\n",
        "fp.close()"
      ],
      "execution_count": 217,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YWbCra3cfeI1",
        "outputId": "b8823e1c-a7f9-46f8-ff6a-5a935addba86"
      },
      "source": [
        "#cut work\n",
        "import jieba\n",
        "import codecs \n",
        "temp = x[500]\n",
        "temp"
      ],
      "execution_count": 227,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['異裂', '2019-01-16', '《異裂》是M.']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 227
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qf_d_JZb-Oy1"
      },
      "source": [
        "#from sklearn import feature_extraction\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "#get the word\n",
        "#clean all the stop word\n",
        "\n",
        "tempCutList = []\n",
        "for data in temp:\n",
        "  cutDataList = []\n",
        "  cutDataList += [word for word in jieba.cut(data[2],cut_all=False) if word not in contents]\n",
        "  tempCutList.append(\" \".join(cutDataList))\n"
      ],
      "execution_count": 220,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uHEb_4GgCFbl"
      },
      "source": [
        "vectorizer = CountVectorizer() # counting each word in list\n",
        "transform = TfidfTransformer() # calculate TFIED value for each word\n",
        "\n",
        "tfidf = transform.fit_transform(vectorizer.fit_transform(tempCutList)) #t.fit =>cal tdidf ,#v.fit =>change words to t.f\n",
        "words = vectorizer.get_feature_names() # get all word \n",
        "\n",
        "weight = tfidf.toarray()\n",
        "for i in range(len(weight)):\n",
        "  print(\"------------Intro\",i,\"Term and TF-IDF:\")\n",
        "  for j in range(len(words)):\n",
        "    print(words[j],weight[i][j])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lza9IEBNGa45"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}